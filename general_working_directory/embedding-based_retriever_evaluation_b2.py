import argparse
import json
from openai import OpenAI
import pandas as pd
import numpy as np
from numpy.linalg import norm
from declarations import evaluation_samples

def run(args):
    df = pd.read_csv(args.embeddings, index_col=0, nrows=None)
    iris = df.index.values.tolist()
    client = OpenAI(base_url="http://tentris-ml.cs.upb.de:8502/v1", api_key="token-tentris-upb")
    docs = np.array(df.values)
    docs_norms = docs / norm(docs, axis=1, keepdims=True)

    df = pd.read_csv("second_benchmark.csv", index_col=0, nrows=None)
    knn = df.values.tolist()

    results = dict()
    count = 0

    if "third" in args.embeddings:
        output = "evaluation_results_embedding-based_KG3_b2.json"
    elif "second" in args.embeddings:
        output = "evaluation_results_embedding-based_KG2_b2.json"
    else:
        raise Exception(
            "Please use the path of a file generated by 'docs_embedding_generation.py' script")

    for target_iri, query in evaluation_samples.items():
        try:
            qr = np.array(client.embeddings.create(input=[query], model="tentris").data[0].embedding)
            qr_norms = qr / norm(qr)
            cosine_similarities = (docs_norms @ qr_norms).flatten()

            best_score = -1
            target_iri_index = iris.index(target_iri)

            for neighbor in knn[target_iri_index]:
                neighbor_score = cosine_similarities[neighbor]
                if neighbor_score > best_score:
                    best_score = neighbor_score

            cosine_similarities = cosine_similarities.tolist()
            cosine_similarities.sort(reverse=True)
            placement = cosine_similarities.index(best_score)
            results[target_iri] = placement

            count += 1
            print(f"Done {count}/100 {target_iri} with placement: {placement:,}/45,623")
        except Exception as e:
            # just for debugging purposes
            print(e)
            print(target_iri)
            print(query)
            with open("evaluation_results2_embedding-based_uncompleted.json", "w") as outfile:
                json.dump(results, outfile)

    with open(output, "w") as outfile:
        json.dump(results, outfile)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('embeddings', help="Path of the csv file storing document embeddings.",
                        default="embeddings_third_kg.csv")
    args = parser.parse_args()
    run(args)
