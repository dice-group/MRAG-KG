import csv
from openai import OpenAI
from owlapy.iri import IRI
from owlapy.owl_ontology_manager import OntologyManager
from owlapy.owl_property import OWLDataProperty
from owlapy.owl_reasoner import OntologyReasoner, FastInstanceCheckerReasoner
import argparse
def run(args):
    manager = OntologyManager()
    filepath = "file://" + args.kg_path
    ontology = manager.load_ontology(IRI.create(filepath))
    base_reasoner = OntologyReasoner(ontology)
    reasoner = FastInstanceCheckerReasoner(base_reasoner=base_reasoner, ontology=ontology)
    dprop2 = OWLDataProperty(IRI.create("http://example.org/hasDescription"))
    dprop3 = OWLDataProperty(IRI.create("http://example.org/hasLLMDescription"))

    if "third" in args.kg_path:
        output = "embeddings_third_kg.csv"
        third = True
    elif "second" in args.kg_path:
        output = "embeddings_second_kg.csv"
        third = False
    else:
        raise Exception("Please use the path of a file generated by "
                        "'second_kg_generation.py' script or 'third_kg_generation.py' script")
    with open(output, mode='a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["IRI"] + [f"{i}" for i in range(4095)])
        client = OpenAI(base_url="http://tentris-ml.cs.upb.de:8502/v1", api_key="token-tentris-upb")
        count = 0
        for image_ind in ontology.individuals_in_signature():
            llm_description = ""
            if third:
                llm_description = str(list(reasoner.data_property_values(image_ind, dprop3))[0].get_literal())
                if len(llm_description) > 4000:
                    # in some rare occasions the LLM generation process is bugged and there is a repeat of words in
                    # the LLM-generated description. The description limit is set to 4000 characters. The average
                    # description length is < 1000.
                    llm_description = llm_description[:4000]
            all_descriptions = ""
            for d in list(reasoner.data_property_values(image_ind, dprop2)):
                all_descriptions = all_descriptions + d.get_literal() + "\n"
            image_iri = image_ind.str
            responses = client.embeddings.create(input=[all_descriptions + "\n " + llm_description], model="tentris")
            writer.writerow([image_iri] + responses.data[0].embedding)
            count += 1
            print(f"{image_iri}: {count:,}/45,623")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('kg_path', help="Path of the knowledge graph to retrieve documents",
                        default="fashionpedia-third-generation.owl")
    args = parser.parse_args()
    run(args)
